/*
    Copyright (C) 2020 by the NebulaStream project (https://nebula.stream)

    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at

        https://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
    limitations under the License.
*/

#ifndef INCLUDE_QUERY_MANAGER_HPP_
#define INCLUDE_QUERY_MANAGER_HPP_

#include <Phases/ConvertLogicalToPhysicalSource.hpp>
#include <Plans/Query/QuerySubPlanId.hpp>
#include <Runtime/BufferManager.hpp>
#include <Runtime/Execution/ExecutablePipeline.hpp>
#include <Runtime/Execution/ExecutableQueryPlan.hpp>
#include <Runtime/Execution/ExecutableQueryPlanStatus.hpp>
#include <Runtime/NodeEngineForwaredRefs.hpp>
#include <Runtime/QueryStatistics.hpp>
#include <Runtime/Reconfigurable.hpp>
#include <Runtime/ReconfigurationMessage.hpp>
#include <Runtime/Task.hpp>
#include <Sources/DataSource.hpp>
#include <State/StateManager.hpp>
#include <Util/ThreadBarrier.hpp>
#include <Util/VirtualEnableSharedFromThis.hpp>
#include <Util/libcuckoo/cuckoohash_map.hh>
#include <Windowing/WindowHandler/AbstractWindowHandler.hpp>
#include <chrono>
#include <condition_variable>
#include <deque>
#include <map>
#include <memory>
#include <mutex>
#include <shared_mutex>
#include <thread>
#include <unordered_map>
#include <unordered_set>

#if defined(NES_USE_MPMC_BLOCKING_CONCURRENT_QUEUE) || NES_USE_ONE_QUEUE_PER_NUMA_NODE
#include <folly/MPMCQueue.h>
#include <folly/concurrency/UnboundedQueue.h>
#endif

namespace NES {
namespace Runtime {

class ThreadPool;
using ThreadPoolPtr = std::shared_ptr<ThreadPool>;// TODO consider moving this atomic in c++20

/**
 * @brief the query manager is the central class to process queries.
 * It is source-driven. Each incoming buffer will add a task to the queue.
 * The query manager maintains three structures:
 * 1.) a data_source map to map one data source to N queries
 * 2.) a window map to map one window to N queries TODO:maybe should be removed later
 * 3.) a data_sink to map one data sink to N queries
 * @Limitations:
 *    - statistics do not cover intermediate buffers
 */
class QueryManager : public NES::detail::virtual_enable_shared_from_this<QueryManager, false>, public Reconfigurable {
    using inherited0 = NES::detail::virtual_enable_shared_from_this<QueryManager, false>;
    using inherited1 = Reconfigurable;

    enum QueryManagerStatus : uint8_t { Created, Running, Stopped, Destroyed, Failed };

  public:
    QueryManager() = delete;
    QueryManager(const QueryManager&) = delete;
    QueryManager& operator=(const QueryManager&) = delete;

    /**
     * @brief
     * @param bufferManager
     */
    explicit QueryManager(std::vector<BufferManagerPtr> bufferManagers,
                          uint64_t nodeEngineId,
                          uint16_t numThreads,
                          HardwareManagerPtr,
                          std::vector<uint64_t> workerToCoreMapping = {});

    ~QueryManager() NES_NOEXCEPT(false) override;

    /**
     * @brief register a query by extracting sources, windows and sink and add them to
     * respective map
     * @param QueryExecutionPlan to be deployed
     */
    bool registerQuery(const Execution::ExecutableQueryPlanPtr& qep);

    /**
     * @brief deregister a query by extracting sources, windows and sink and remove them
     * from respective map
     * @param QueryExecutionPlan to be deployed
     * @return bool indicating if register was successful
     */
    bool deregisterQuery(const Execution::ExecutableQueryPlanPtr& qep);

    /**
     * @brief process task from task queue
     * @param bool indicating if the thread pool is still running
     * @param worker context
     * @return an execution result
     *
     */
#if defined(NES_USE_MPMC_BLOCKING_CONCURRENT_QUEUE) || defined(NES_USE_ONE_QUEUE_PER_NUMA_NODE)
    ExecutionResult processNextTask(bool running, WorkerContext& workerContext);
#else
    ExecutionResult processNextTask(std::atomic<bool>& running, WorkerContext& workerContext);
#endif

    /**
     * @brief add work to the query manager, this methods is source-driven and is called
     * for each incoming buffer
     * @param Pointer to the tuple buffer containing the data
     * @param Pointer to the source at which the data arrived
     */
    void addWork(OperatorId sourceId, TupleBuffer& buf);

    /**
     * @brief add work to the query manager, this methods is source-driven and is called
     * for each buffer generated by the window trigger
     * @param Pointer to the tuple buffer containing the data
     * @param Pointer to the pipeline stage that will be executed next
     */
    void addWorkForNextPipeline(TupleBuffer& buffer, Execution::SuccessorExecutablePipeline executable);

    void postReconfigurationCallback(ReconfigurationMessage& task) override;

    void reconfigure(ReconfigurationMessage&, WorkerContext& context) override;

    /**
     * @brief retrieve the execution status of a given local query sub plan id.
     * @param id : the query sub plan id
     * @return status of the query sub plan
     */
    Execution::ExecutableQueryPlanStatus getQepStatus(QuerySubPlanId id);

    /**
     * @brief get general statistics of QueryManager and Buffer Manager
     */
    std::string getQueryManagerStatistics();

    /**
     * @brief method to start a query
     * @param qep of the query to start
     * @return bool indicating success
     */
    bool startQuery(const Execution::ExecutableQueryPlanPtr& qep, StateManagerPtr stateManager);

    /**
     * @brief method to start a query
     * @param qep of the query to start
     * @param graceful stop the query gracefully or not
     * @return bool indicating success
     */
    bool stopQuery(const Execution::ExecutableQueryPlanPtr& qep, bool graceful = false);

    /**
    * @brief method to fail a query
    * @param qep of the query to fail
    * @return bool indicating success
    */
    static bool failQuery(const Execution::ExecutableQueryPlanPtr& qep);

    /**
     * @brief notify all waiting threads in getWork() to wake up and finish up
     */
    void poisonWorkers();

    /**
     * @brief reset query manager to intial state
     */
    void destroy();

    /**
     * @brief method to return the query statistics
     * @param qep of the particular query
     * @return
     */
    QueryStatisticsPtr getQueryStatistics(QuerySubPlanId qepId);

    uint64_t getNodeId() const;

    /**
     * @brief this methods adds a reconfiguration task on the worker queue
     * @return true if the reconfiguration task was added correctly on the worker queue
     * N.B.: this does not not mean that the reconfiguration took place but it means that it
     * was scheduled to be executed!
     * @param queryExecutionPlanId: the local QEP to reconfigure
     * @param reconfigurationDescriptor: what to do
     * @param blocking: whether to block until the reconfiguration is done. Mind this parameter because it blocks!
     */
    bool addReconfigurationMessage(QuerySubPlanId queryExecutionPlanId,
                                   const ReconfigurationMessage& reconfigurationMessage,
                                   bool blocking = false);

    /**
     * @brief introduces end of stream to all QEPs connected to this source
     * @param source the actual source
     * @param graceful hard or soft termination
     * @return true if it went through
     */
    bool addEndOfStream(const DataSourcePtr& source, bool graceful = true) {
        return addEndOfStream(source->getOperatorId(), graceful);
    }

    /**
     * @brief introduces end of stream to all QEPs connected to this source
     * @param operatorId the id of the source
     * @param graceful hard or soft termination
     * @return true if it went through
     */
    bool addEndOfStream(OperatorId sourceId, bool graceful = true);

    /**
     * @return true if thread pool is running
     */
    bool isThreadPoolRunning() const;

    /**
     * @brief get number of tasks in the queue
     * @return task count
     */
    uint64_t getNumberOfTasksInWorkerQueue() const;

    template<typename T>
    struct alignas(2 * 64) AtomicCounter {
        explicit AtomicCounter(T defValue = 0) : counter(defValue) {}
        AtomicCounter(const AtomicCounter<T>& other) : counter(other.counter.load()) {}
        AtomicCounter<T>& operator=(const AtomicCounter<T>& other) {
            counter.store(other.counter.load());
            return *this;
        }
        operator T() { return counter.load(); }
        T fetch_add(T delta) { return counter.fetch_add(delta); }
        std::atomic<T> counter;
    };
    static_assert(sizeof(AtomicCounter<uint64_t>) == 2 * 64);

    size_t getCurrentTaskSum();

  private:
    friend class ThreadPool;
    friend class NodeEngine;
    /**
    * @brief method to start the thread pool
    * @param nodeEngineId the id of the owning node engine
     * @param numberOfBuffersPerWorker
    * @return bool indicating success
    */
    bool startThreadPool(uint64_t numberOfBuffersPerWorker);

    /**
     * @brief finalize task execution by:
     * 1.) update statistics (number of processed tuples and tasks)
     * 2.) release input buffer (give back to the buffer manager)
     * @param reference to processed task
     * @oaram reference to worker context
     */
    void completedWork(Task& task, WorkerContext& workerContext);

    ExecutionResult terminateLoop(WorkerContext&);

    bool addSoftEndOfStream(OperatorId sourceId);
    bool addHardEndOfStream(OperatorId sourceId);

  private:
    uint64_t nodeEngineId;

    ThreadPoolPtr threadPool{nullptr};

    // TODO remove these unnecessary structures
    std::map<OperatorId, Execution::ExecutableQueryPlanPtr> sourceIdToExecutableQueryPlanMap;
    std::map<OperatorId, std::vector<Execution::SuccessorExecutablePipeline>> sourceIdToSuccessorMap;
    std::map<OperatorId, std::vector<OperatorId>> queryMapToOperatorId;

    std::unordered_map<QuerySubPlanId, Execution::ExecutableQueryPlanPtr> runningQEPs;

    //TODO:check if it would be better to put it in the thread context
    mutable std::mutex statisticsMutex;
    cuckoohash_map<QuerySubPlanId, QueryStatisticsPtr> queryToStatisticsMap;

    std::vector<BufferManagerPtr> bufferManagers;
    Execution::ExecutablePipelineStagePtr reconfigurationExecutable;

    uint16_t numThreads;
    std::vector<uint64_t> workerToCoreMapping;
    //    mutable std::shared_mutex queryMutex;
    mutable std::recursive_mutex queryMutex;
    HardwareManagerPtr hardwareManager;
#ifdef NES_USE_MPMC_BLOCKING_CONCURRENT_QUEUE
    folly::MPMCQueue<Task> taskQueue;
#elif NES_USE_ONE_QUEUE_PER_NUMA_NODE
    std::vector<folly::MPMCQueue<Task>> taskQueues;
    std::shared_ptr<Runtime::HardwareManager> hardwareManager;
    std::map<size_t, size_t> numaRegionToThreadMap;
    size_t numberOfQueues = 1;
#else
    std::deque<Task> taskQueue;
    mutable std::mutex workMutex;
    std::condition_variable cv;
#endif
    std::atomic<QueryManagerStatus> queryManagerStatus{Created};
    std::vector<AtomicCounter<uint64_t>> tempCounterTasksCompleted;
};

using QueryManagerPtr = std::shared_ptr<QueryManager>;

}// namespace Runtime
}// namespace NES
#endif /* INCLUDE_query manager_H_ */
