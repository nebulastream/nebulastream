{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Benchmark Analysis Notebook\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, fixed\n",
    "import subprocess\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Define query descriptions\n",
    "QUERY_DESCRIPTIONS = {\n",
    "    '01': 'Filter 5% selectivity',\n",
    "    '02': 'Filter 50% selectivity',\n",
    "    '03': 'Filter 95% selectivity',\n",
    "    '04': 'Map',\n",
    "    '05': 'Filter and Map 5% selectivity',\n",
    "    '06': 'Filter and Map 50% selectivity',\n",
    "    '1': 'Filter 5% selectivity',\n",
    "    '2': 'Filter 50% selectivity',\n",
    "    '3': 'Filter 95% selectivity',\n",
    "    '4': 'Map',\n",
    "    '5': 'Filter and Map 5% selectivity',\n",
    "    '6': 'Filter and Map 50% selectivity'\n",
    "}\n",
    "\n",
    "# Define color maps for buffer sizes\n",
    "ROW_COLORS = {\n",
    "    '4000': '#1f77b4',     # blue\n",
    "    '400000': '#2a9df4',   # lighter blue\n",
    "    '20000000': '#7fbfff'  # lightest blue\n",
    "}\n",
    "\n",
    "COL_COLORS = {\n",
    "    '4000': '#ff7f0e',     # orange\n",
    "    '400000': '#ffb14e',   # lighter orange\n",
    "    '20000000': '#ffd699'  # lightest orange\n",
    "}\n",
    "\n",
    "# Define pipeline colors\n",
    "PIPELINE_COLORS = {\n",
    "    '1': '#1f77b4',  # blue\n",
    "    '2': '#ff7f0e',  # orange\n",
    "    '3': '#2ca02c',  # green\n",
    "    '4': '#d62728',  # red\n",
    "    '5': '#9467bd',  # purple\n",
    "    '6': '#8c564b',  # brown\n",
    "    '7': '#e377c2',  # pink\n",
    "    '8': '#7f7f7f',  # gray\n",
    "    '9': '#bcbd22',  # olive\n",
    "    '10': '#17becf'  # teal\n",
    "}\n",
    "\n",
    "# ---- Section 1: Load and Process Benchmark Data ----\n",
    "# Allows selecting and processing trace files from a benchmark run\n",
    "\n",
    "def get_benchmark_dirs():\n",
    "    \"\"\"Get list of available benchmark directories\"\"\"\n",
    "    project_dir = \"/home/user/CLionProjects/nebulastream\"\n",
    "    stats_dir = f\"{project_dir}/Testing/stats\"\n",
    "    return sorted([d for d in os.listdir(stats_dir)\n",
    "                   if os.path.isdir(os.path.join(stats_dir, d)) and d.startswith(\"benchmark\")])\n",
    "\n",
    "def process_trace_files(benchmark_dir):\n",
    "    \"\"\"Process trace files in the given directory using enginestatsread.py\"\"\"\n",
    "    project_dir = \"/home/user/CLionProjects/nebulastream\"\n",
    "    script_path = f\"{project_dir}/Testing/scripts/enginestatsread.py\"\n",
    "\n",
    "    # Run the enginestatsread.py script to process trace files\n",
    "    cmd = f\"python3 {script_path} {benchmark_dir}\"\n",
    "    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "\n",
    "    print(result.stdout)\n",
    "    if result.stderr:\n",
    "        print(\"Errors:\", result.stderr)\n",
    "\n",
    "    # Check for the CSV file\n",
    "    csv_path = f\"{benchmark_dir}/{os.path.basename(benchmark_dir)}.csv\"\n",
    "    if os.path.exists(csv_path):\n",
    "        return pd.read_csv(csv_path)\n",
    "    else:\n",
    "        # Try to find any CSV file\n",
    "        csv_files = [f for f in os.listdir(benchmark_dir) if f.endswith('.csv')]\n",
    "        if csv_files:\n",
    "            return pd.read_csv(f\"{benchmark_dir}/{csv_files[0]}\")\n",
    "        else:\n",
    "            print(f\"No CSV file found in {benchmark_dir}\")\n",
    "            return None\n",
    "\n",
    "# UI for selecting and processing benchmark data\n",
    "benchmark_dirs = get_benchmark_dirs()\n",
    "benchmark_dropdown = widgets.Dropdown(\n",
    "    options=benchmark_dirs,\n",
    "    description='Benchmark:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "process_button = widgets.Button(description=\"Process Data\")\n",
    "output = widgets.Output()\n",
    "\n",
    "@output.capture()\n",
    "def on_process_button_clicked(b):\n",
    "    selected_dir = \"/home/user/CLionProjects/nebulastream/Testing/stats/\" + benchmark_dropdown.value\n",
    "    print(f\"Processing benchmark data from {selected_dir}...\")\n",
    "    global df\n",
    "    df = process_trace_files(selected_dir)\n",
    "    if df is not None:\n",
    "        print(f\"Loaded {len(df)} records into DataFrame\")\n",
    "        display(df.head())\n",
    "    else:\n",
    "        print(\"Failed to load data\")\n",
    "\n",
    "process_button.on_click(on_process_button_clicked)\n",
    "\n",
    "display(widgets.VBox([benchmark_dropdown, process_button, output]))\n",
    "\n",
    "# ---- Section 2: Interactive Analysis Functions ----\n",
    "\n",
    "def get_query_label(query_id):\n",
    "    \"\"\"Get descriptive label for query ID.\"\"\"\n",
    "    query_id = str(query_id)  # Ensure string type\n",
    "    if query_id in QUERY_DESCRIPTIONS:\n",
    "        return f\"Q{query_id}: {QUERY_DESCRIPTIONS[query_id]}\"\n",
    "    return f\"Query {query_id}\"\n",
    "\n",
    "def scale_time_value(values):\n",
    "    \"\"\"Dynamically scale time values to appropriate units.\"\"\"\n",
    "    values = values.dropna()\n",
    "    if len(values) == 0:\n",
    "        return values, \"s\"\n",
    "\n",
    "    max_val = np.max(values)\n",
    "    if max_val < 0.001:  # nanoseconds range\n",
    "        return values * 1e9, \"ns\"\n",
    "    elif max_val < 1:  # milliseconds range\n",
    "        return values * 1e3, \"ms\"\n",
    "    else:  # seconds range\n",
    "        return values, \"s\"\n",
    "\n",
    "# Function to plot query duration comparison\n",
    "def plot_query_duration_comparison(df, query=None, threads=None):\n",
    "    if df is None:\n",
    "        print(\"No data loaded. Please process a benchmark first.\")\n",
    "        return\n",
    "\n",
    "    # Filter data based on parameters\n",
    "    filtered_df = df.copy()\n",
    "    if query is not None:\n",
    "        filtered_df = filtered_df[filtered_df['query'] == str(query)]\n",
    "    if threads is not None:\n",
    "        filtered_df = filtered_df[filtered_df['threads'] == str(threads)]\n",
    "\n",
    "    # Skip if no data\n",
    "    if filtered_df.empty:\n",
    "        print(\"No data matching the selected filters.\")\n",
    "        return\n",
    "\n",
    "    # Add query_label\n",
    "    filtered_df['query_label'] = filtered_df['query'].apply(get_query_label)\n",
    "\n",
    "    # Group by relevant dimensions\n",
    "    grouped = filtered_df.groupby(['query', 'layout', 'buffer_size', 'threads'])\n",
    "\n",
    "    # Calculate mean and std of full_query_duration\n",
    "    agg_df = grouped['full_query_duration'].agg(['mean', 'std']).reset_index()\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(14, 8))\n",
    "\n",
    "    # Use query as x-axis if not filtered\n",
    "    if query is None:\n",
    "        x_dim = 'query'\n",
    "        hue_dim = 'threads' if threads is None else None\n",
    "    else:\n",
    "        # Use threads as x-axis if query is filtered\n",
    "        x_dim = 'threads'\n",
    "        hue_dim = None\n",
    "\n",
    "    # Create bar plot\n",
    "    g = sns.catplot(\n",
    "        data=agg_df,\n",
    "        x=x_dim,\n",
    "        y='mean',\n",
    "        hue=hue_dim,\n",
    "        col='layout',\n",
    "        row='buffer_size',\n",
    "        kind='bar',\n",
    "        height=4,\n",
    "        aspect=1.5,\n",
    "        errorbar=('ci', 95),\n",
    "        legend_out=True\n",
    "    )\n",
    "\n",
    "    # Customize the plot\n",
    "    g.set_axis_labels(\"\" if query is None else \"Thread Count\", \"Query Duration (s)\")\n",
    "    g.set_titles(\"{row_name} | {col_name}\")\n",
    "\n",
    "    # Format y-axis to appropriate scale\n",
    "    for ax in g.axes.flat:\n",
    "        values = ax.get_ylim()\n",
    "        scaled_values, unit = scale_time_value(pd.Series(values))\n",
    "        ax.set_ylim(scaled_values)\n",
    "        ax.set_ylabel(f\"Query Duration ({unit})\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Function to plot pipeline throughput comparison\n",
    "def plot_pipeline_throughput(df, query=None, threads=None, tp_type='eff'):\n",
    "    if df is None:\n",
    "        print(\"No data loaded. Please process a benchmark first.\")\n",
    "        return\n",
    "\n",
    "    # Filter data based on parameters\n",
    "    filtered_df = df.copy()\n",
    "    if query is not None:\n",
    "        filtered_df = filtered_df[filtered_df['query'] == str(query)]\n",
    "    if threads is not None:\n",
    "        filtered_df = filtered_df[filtered_df['threads'] == str(threads)]\n",
    "\n",
    "    # Skip if no data\n",
    "    if filtered_df.empty:\n",
    "        print(\"No data matching the selected filters.\")\n",
    "        return\n",
    "\n",
    "    # Get all pipeline throughput columns\n",
    "    tp_cols = [col for col in filtered_df.columns if f'pipeline_' in col and f'_{tp_type}_tp' in col]\n",
    "\n",
    "    if not tp_cols:\n",
    "        print(f\"No {tp_type} throughput columns found in the data.\")\n",
    "        return\n",
    "\n",
    "    # Extract pipeline IDs\n",
    "    pipeline_ids = sorted(list(set([int(col.split('_')[1]) for col in tp_cols])))\n",
    "\n",
    "    # Prepare data for plotting\n",
    "    plot_data = []\n",
    "\n",
    "    for _, row in filtered_df.iterrows():\n",
    "        for pipeline_id in pipeline_ids:\n",
    "            col = f'pipeline_{pipeline_id}_{tp_type}_tp'\n",
    "            if col in row and not pd.isna(row[col]):\n",
    "                plot_data.append({\n",
    "                    'query': row['query'],\n",
    "                    'layout': row['layout'],\n",
    "                    'buffer_size': row['buffer_size'],\n",
    "                    'threads': row['threads'],\n",
    "                    'pipeline': f'Pipeline {pipeline_id}',\n",
    "                    'throughput': row[col]\n",
    "                })\n",
    "\n",
    "    plot_df = pd.DataFrame(plot_data)\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(14, 8))\n",
    "\n",
    "    g = sns.catplot(\n",
    "        data=plot_df,\n",
    "        x='pipeline',\n",
    "        y='throughput',\n",
    "        hue='buffer_size',\n",
    "        col='layout',\n",
    "        row='threads' if threads is None else None,\n",
    "        kind='bar',\n",
    "        height=4,\n",
    "        aspect=1.5,\n",
    "        palette='viridis',\n",
    "        log=True,  # Log scale for throughput\n",
    "        legend_out=True\n",
    "    )\n",
    "\n",
    "    tp_type_label = 'Effective' if tp_type == 'eff' else 'Computational'\n",
    "    g.set_axis_labels(\"Pipeline\", f\"{tp_type_label} Throughput (tuples/s)\")\n",
    "    g.set_titles(\"{row_name} | {col_name}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Function to plot pipeline time percentage\n",
    "def plot_pipeline_percentages(df, query=None, threads=None):\n",
    "    if df is None:\n",
    "        print(\"No data loaded. Please process a benchmark first.\")\n",
    "        return\n",
    "\n",
    "    # Filter data based on parameters\n",
    "    filtered_df = df.copy()\n",
    "    if query is not None:\n",
    "        filtered_df = filtered_df[filtered_df['query'] == str(query)]\n",
    "    if threads is not None:\n",
    "        filtered_df = filtered_df[filtered_df['threads'] == str(threads)]\n",
    "\n",
    "    # Skip if no data\n",
    "    if filtered_df.empty:\n",
    "        print(\"No data matching the selected filters.\")\n",
    "        return\n",
    "\n",
    "    # Get all pipeline time percentage columns\n",
    "    pct_cols = [col for col in filtered_df.columns if 'pipeline_' in col and 'time_pct' in col]\n",
    "\n",
    "    if not pct_cols:\n",
    "        print(\"No pipeline time percentage columns found in the data.\")\n",
    "        return\n",
    "\n",
    "    # Extract pipeline IDs\n",
    "    pipeline_ids = sorted(list(set([int(col.split('_')[1]) for col in pct_cols])))\n",
    "\n",
    "    # Prepare data for plotting\n",
    "    plot_data = []\n",
    "\n",
    "    for _, row in filtered_df.iterrows():\n",
    "        config_label = f\"{row['layout']}\\n{row['buffer_size']}, {row['threads']}T\"\n",
    "\n",
    "        for pipeline_id in pipeline_ids:\n",
    "            col = f'pipeline_{pipeline_id}_time_pct'\n",
    "            if col in row and not pd.isna(row[col]):\n",
    "                plot_data.append({\n",
    "                    'query': row['query'],\n",
    "                    'config': config_label,\n",
    "                    'pipeline': f'Pipeline {pipeline_id}',\n",
    "                    'percentage': row[col],\n",
    "                    'color': PIPELINE_COLORS.get(str(pipeline_id), f'C{pipeline_id % 10}')\n",
    "                })\n",
    "\n",
    "    plot_df = pd.DataFrame(plot_data)\n",
    "\n",
    "    # Create query-specific plots\n",
    "    if query is None:\n",
    "        for q in sorted(plot_df['query'].unique()):\n",
    "            q_df = plot_df[plot_df['query'] == q]\n",
    "            _create_pipeline_percentage_plot(q_df, get_query_label(q))\n",
    "    else:\n",
    "        _create_pipeline_percentage_plot(plot_df, get_query_label(query))\n",
    "\n",
    "def _create_pipeline_percentage_plot(df, title):\n",
    "    plt.figure(figsize=(14, 8))\n",
    "\n",
    "    # Pivot data for stacked bar chart\n",
    "    pivot_df = df.pivot_table(\n",
    "        index='config',\n",
    "        columns='pipeline',\n",
    "        values='percentage',\n",
    "        aggfunc='mean'\n",
    "    ).fillna(0)\n",
    "\n",
    "    # Get colors\n",
    "    colors = [df[df['pipeline'] == p]['color'].iloc[0] for p in pivot_df.columns]\n",
    "\n",
    "    # Plot stacked bars\n",
    "    ax = pivot_df.plot(\n",
    "        kind='bar',\n",
    "        stacked=True,\n",
    "        figsize=(14, 8),\n",
    "        color=colors\n",
    "    )\n",
    "\n",
    "    # Add percentage labels\n",
    "    for i, (_, row) in enumerate(pivot_df.iterrows()):\n",
    "        bottom = 0\n",
    "        for j, val in enumerate(row):\n",
    "            if val > 5:  # Only show label if percentage > 5%\n",
    "                ax.text(\n",
    "                    i, bottom + val/2,\n",
    "                    f\"{pivot_df.columns[j]}\\n{val:.1f}%\",\n",
    "                    ha='center', va='center',\n",
    "                    color='white', fontweight='bold'\n",
    "                )\n",
    "            bottom += val\n",
    "\n",
    "    plt.title(f'{title}: Percentage of Time Spent in Each Pipeline')\n",
    "    plt.xlabel('Configuration')\n",
    "    plt.ylabel('Percentage of Time (%)')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.legend(title='Pipeline')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ---- Section 3: Interactive UI for analysis ----\n",
    "\n",
    "def interactive_analysis_ui():\n",
    "    if 'df' not in globals():\n",
    "        print(\"No data loaded. Please process a benchmark first.\")\n",
    "        return\n",
    "\n",
    "    global df\n",
    "\n",
    "    queries = ['All'] + sorted(df['query'].unique().tolist())\n",
    "    threads = ['All'] + sorted(df['threads'].unique().tolist())\n",
    "\n",
    "    @interact\n",
    "    def analyze(analysis_type=widgets.Dropdown(\n",
    "        options=[\n",
    "            'Query Duration Comparison',\n",
    "            'Pipeline Throughput (Effective)',\n",
    "            'Pipeline Throughput (Computational)',\n",
    "            'Pipeline Time Percentages'\n",
    "        ],\n",
    "        description='Analysis:'),\n",
    "            query=widgets.Dropdown(\n",
    "                options=queries,\n",
    "                description='Query:'),\n",
    "            threads=widgets.Dropdown(\n",
    "                options=threads,\n",
    "                description='Threads:')):\n",
    "\n",
    "        # Convert 'All' to None for filter functions\n",
    "        query_filter = None if query == 'All' else query\n",
    "        threads_filter = None if threads == 'All' else threads\n",
    "\n",
    "        if analysis_type == 'Query Duration Comparison':\n",
    "            plot_query_duration_comparison(df, query_filter, threads_filter)\n",
    "        elif analysis_type == 'Pipeline Throughput (Effective)':\n",
    "            plot_pipeline_throughput(df, query_filter, threads_filter, tp_type='eff')\n",
    "        elif analysis_type == 'Pipeline Throughput (Computational)':\n",
    "            plot_pipeline_throughput(df, query_filter, threads_filter, tp_type='comp')\n",
    "        elif analysis_type == 'Pipeline Time Percentages':\n",
    "            plot_pipeline_percentages(df, query_filter, threads_filter)\n",
    "\n",
    "# Display the interactive UI\n",
    "display(Markdown(\"## Interactive Analysis\"))\n",
    "display(Markdown(\"First load data using the selection above, then use these controls to analyze the results.\"))\n",
    "interactive_analysis_ui()\n",
    "\n",
    "# ---- Section 4: Run New Benchmarks (Optional) ----\n",
    "\n",
    "def run_new_benchmark_ui():\n",
    "    # Create UI elements for running new benchmarks\n",
    "    layouts = widgets.SelectMultiple(\n",
    "        options=['COLUMNAR_LAYOUT', 'ROW_LAYOUT'],\n",
    "        value=['COLUMNAR_LAYOUT', 'ROW_LAYOUT'],\n",
    "        description='Layouts:',\n",
    "        disabled=False\n",
    "    )\n",
    "\n",
    "    buffer_sizes = widgets.SelectMultiple(\n",
    "        options=['20000000', '400000', '4000'],\n",
    "        value=['400000'],\n",
    "        description='Buffer Sizes:',\n",
    "        disabled=False\n",
    "    )\n",
    "\n",
    "    threads = widgets.SelectMultiple(\n",
    "        options=['1', '2', '4', '8'],\n",
    "        value=['4'],\n",
    "        description='Threads:',\n",
    "        disabled=False\n",
    "    )\n",
    "\n",
    "    queries = widgets.SelectMultiple(\n",
    "        options=['01', '02', '03', '04', '05', '06'],\n",
    "        value=['01'],\n",
    "        description='Queries:',\n",
    "        disabled=False\n",
    "    )\n",
    "\n",
    "    run_button = widgets.Button(description=\"Run Benchmarks\")\n",
    "    run_output = widgets.Output()\n",
    "\n",
    "    @run_output.capture()\n",
    "    def on_run_button_clicked(b):\n",
    "        # Create command to run benchmarks with selected parameters\n",
    "        layouts_str = ' '.join(layouts.value)\n",
    "        buffer_sizes_str = ' '.join(buffer_sizes.value)\n",
    "        threads_str = ' '.join(threads.value)\n",
    "        queries_str = ' '.join(queries.value)\n",
    "\n",
    "        print(f\"Running benchmarks with:\")\n",
    "        print(f\"  Layouts: {layouts_str}\")\n",
    "        print(f\"  Buffer sizes: {buffer_sizes_str}\")\n",
    "        print(f\"  Threads: {threads_str}\")\n",
    "        print(f\"  Queries: {queries_str}\")\n",
    "\n",
    "        cmd = f\"python3 /home/user/CLionProjects/nebulastream/Testing/scripts/benchmark_runner.py --layouts {layouts_str} --buffer-sizes {buffer_sizes_str} --threads {threads_str} --queries {queries_str}\"\n",
    "\n",
    "        # Run the benchmark script\n",
    "        result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "\n",
    "        print(result.stdout)\n",
    "        if result.stderr:\n",
    "            print(\"Errors:\", result.stderr)\n",
    "\n",
    "        # Update benchmark dropdown with new directory\n",
    "        global benchmark_dirs, benchmark_dropdown\n",
    "        benchmark_dirs = get_benchmark_dirs()\n",
    "        benchmark_dropdown.options = benchmark_dirs\n",
    "        if benchmark_dirs:\n",
    "            benchmark_dropdown.value = benchmark_dirs[-1]\n",
    "\n",
    "    run_button.on_click(on_run_button_clicked)\n",
    "\n",
    "    display(Markdown(\"## Run New Benchmarks\"))\n",
    "    display(Markdown(\"Select parameters and run new benchmarks. This will take significant time depending on selections.\"))\n",
    "    display(widgets.VBox([layouts, buffer_sizes, threads, queries, run_button, run_output]))\n",
    "\n",
    "run_new_benchmark_ui()"
   ],
   "id": "9e352d62f14b6a98"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
